"""
FAR_stock - Financial AI Recommender for Stock Surge
ãƒ¡ã‚¤ãƒ³Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

5ã‚¿ãƒ–æ§‹æˆ:
1. ğŸ“Œ å€‹åˆ¥éŠ˜æŸ„åˆ†æï¼ˆãƒãƒ£ãƒ¼ãƒˆ + ã‚·ã‚°ãƒŠãƒ« + MLç¢ºç‡ï¼‰
2. ğŸ” ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
3. ğŸš€ æ€¥é¨°å€™è£œAIæ¤œçŸ¥ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰
4. ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
5. â­ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆç®¡ç†
"""

import os
import sys
import time
import streamlit as st
import pandas as pd
import numpy as np

# ãƒ‘ã‚¹è¨­å®š
sys.path.insert(0, os.path.dirname(__file__))

from config import ScanConfig, ModelConfig, APIConfig
from src.data_loader import get_stock_data, fetch_jpx_tickers
from src.analyzer import (
    add_technical_indicators, analyze_term_signal,
    analyze_speculative_signal
)
from src.feature_engineering import FeatureEngineer
from src.ml_model import SurgePredictor
from src.recommender import StockRecommender
from src.utils import validate_ticker_symbol, plot_stock_chart
from src import db

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page Config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="FAR_stock - æ€¥é¨°æ ªAIæ¨è–¦",
    page_icon="ğŸš€",
    layout="wide"
)

st.title("ğŸš€ FAR_stock - æ€¥é¨°æ ªAIãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼")
st.caption("Financial AI Recommender for Stock Surge | LightGBM + ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¨è–¦")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Model Loading (Cached)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_model():
    """å­¦ç¿’æ¸ˆã¿LightGBMãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰ã€‚"""
    predictor = SurgePredictor()
    model_path = "models/lgbm_surge_v1.pkl"
    if os.path.exists(model_path):
        try:
            predictor.load(model_path)
            return predictor
        except Exception as e:
            st.warning(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    return predictor


@st.cache_data(ttl=3600)
def load_tickers():
    """éŠ˜æŸ„ä¸€è¦§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§å–å¾—ã™ã‚‹ã€‚"""
    return fetch_jpx_tickers()


model = load_model()
recommender = StockRecommender(model=model)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar - Model Training & Watchlist
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†")

# Model Status
model_status = "âœ… å­¦ç¿’æ¸ˆã¿" if model.model is not None else "âš ï¸ æœªå­¦ç¿’"
st.sidebar.markdown(f"**MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹**: {model_status}")

from config import GPU_AVAILABLE
gpu_status = "ğŸŸ¢ GPU (RTX)" if GPU_AVAILABLE else "ğŸ”´ CPU"
st.sidebar.markdown(f"**ãƒ‡ãƒã‚¤ã‚¹**: {gpu_status}")

if model.model is not None and model.metrics_:
    m = model.metrics_
    st.sidebar.markdown(f"- AUC: {m.get('auc_roc', 0):.3f}")
    st.sidebar.markdown(f"- P@{ModelConfig.TOP_K}: {m.get('precision_at_k', 0):.3f}")

# Train Button
if st.sidebar.button("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’/å†å­¦ç¿’"):
    with st.sidebar.status("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...", expanded=True) as status:
        st.write("éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—ä¸­...")
        tickers_df = load_tickers()

        if tickers_df.empty:
            st.sidebar.error("éŠ˜æŸ„ä¸€è¦§ã®å–å¾—ã«å¤±æ•—")
        else:
            # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿åé›†: å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + ä½ä½æ ªé‡ç‚¹
            st.write("å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + ä½ä½æ ªé‡ç‚¹ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­...")

            # 1. å„ã‚»ã‚¯ã‚¿ãƒ¼ã‹ã‚‰å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            sectors = tickers_df['Sector'].unique()
            per_sector = max(4, 150 // len(sectors))  # å…¨ä½“ã§ç´„150éŠ˜æŸ„
            stratified = []
            for sector in sectors:
                sector_df = tickers_df[tickers_df['Sector'] == sector]
                n_sample = min(per_sector, len(sector_df))
                stratified.append(sector_df.sample(n=n_sample, random_state=42))
            stratified_df = pd.concat(stratified, ignore_index=True)

            # 2. ä½ä½æ ªã‚’è¿½åŠ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§é«˜é€ŸåŒ–)
            #    æ ªä¾¡1,000å††ä»¥ä¸‹ã®éŠ˜æŸ„ã‚’é‡ç‚¹çš„ã«è¿½åŠ 
            st.write("ğŸ“‰ **Phase 1/3**: ä½ä½æ ªã®æ ªä¾¡ãƒã‚§ãƒƒã‚¯ä¸­...")
            low_price_candidates = []
            check_tickers = tickers_df[
                ~tickers_df['Ticker'].isin(stratified_df['Ticker'])
            ]['Ticker'].tolist()

            import random
            import yfinance as yf
            random.seed(42)
            check_sample = random.sample(check_tickers, min(500, len(check_tickers)))

            # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§é«˜é€ŸåŒ– (50éŠ˜æŸ„ãšã¤)
            progress_phase1 = st.progress(0, text="ä½ä½æ ªãƒã‚§ãƒƒã‚¯ä¸­...")
            chunk_size = 50
            for chunk_i in range(0, len(check_sample), chunk_size):
                chunk = check_sample[chunk_i:chunk_i + chunk_size]
                try:
                    data = yf.download(chunk, period="5d", progress=False, threads=True)
                    if not data.empty:
                        if isinstance(data.columns, pd.MultiIndex):
                            for t in chunk:
                                try:
                                    close = data.xs(t, axis=1, level=1)['Close'].dropna()
                                    if not close.empty and close.iloc[-1] <= ScanConfig.MAX_PRICE:
                                        low_price_candidates.append(t)
                                except (KeyError, Exception):
                                    pass
                        elif len(chunk) == 1 and 'Close' in data.columns:
                            if data['Close'].iloc[-1] <= ScanConfig.MAX_PRICE:
                                low_price_candidates.append(chunk[0])
                except Exception:
                    pass

                progress_phase1.progress(
                    min((chunk_i + chunk_size), len(check_sample)) / len(check_sample),
                    text=f"ä½ä½æ ªãƒã‚§ãƒƒã‚¯: {min(chunk_i+chunk_size, len(check_sample))}/{len(check_sample)} (ç™ºè¦‹: {len(low_price_candidates)}ä»¶)"
                )

                if len(low_price_candidates) >= 50:
                    break

            progress_phase1.progress(1.0, text=f"ä½ä½æ ªãƒã‚§ãƒƒã‚¯å®Œäº† âœ… ({len(low_price_candidates)}ä»¶)")

            # 3. çµ±åˆ: å±¤åŒ–ã‚µãƒ³ãƒ—ãƒ« + ä½ä½æ ªè¿½åŠ 
            all_sample = list(set(
                stratified_df['Ticker'].tolist() + low_price_candidates
            ))
            sample_tickers = all_sample

            st.write(
                f"**{len(sample_tickers)}éŠ˜æŸ„** ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº† "
                f"(å±¤åŒ–: {len(stratified_df)}éŠ˜æŸ„ Ã— {len(sectors)}ã‚»ã‚¯ã‚¿ãƒ¼, "
                f"ä½ä½æ ªè¿½åŠ : {len(low_price_candidates)}éŠ˜æŸ„)"
            )

            # 4. ç‰¹å¾´é‡ç”Ÿæˆ & ãƒ‡ãƒ¼ã‚¿åé›† (ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§é«˜é€ŸåŒ–)
            st.write("ğŸ“Š **Phase 2/3**: ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾— & ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
            fe = FeatureEngineer()
            all_X = []
            all_y = []
            fetched_count = 0

            # yf.download ã§ä¸€æ‹¬å–å¾— (50éŠ˜æŸ„ãƒãƒ£ãƒ³ã‚¯)
            progress_phase2 = st.progress(0, text="ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
            dl_chunk_size = 50
            all_data = {}
            for chunk_i in range(0, len(sample_tickers), dl_chunk_size):
                chunk = sample_tickers[chunk_i:chunk_i + dl_chunk_size]
                try:
                    data = yf.download(chunk, period="1y", progress=False, threads=True)
                    if not data.empty:
                        if isinstance(data.columns, pd.MultiIndex):
                            for t in chunk:
                                try:
                                    df_t = data.xs(t, axis=1, level=1).dropna(how='all')
                                    if not df_t.empty and len(df_t) >= 100:
                                        all_data[t] = df_t
                                except (KeyError, Exception):
                                    pass
                        elif len(chunk) == 1 and len(data) >= 100:
                            all_data[chunk[0]] = data
                except Exception:
                    pass

                progress_phase2.progress(
                    min(chunk_i + dl_chunk_size, len(sample_tickers)) / len(sample_tickers),
                    text=f"ãƒ‡ãƒ¼ã‚¿å–å¾—: {min(chunk_i+dl_chunk_size, len(sample_tickers))}/{len(sample_tickers)}"
                )

            st.write(f"å–å¾—å®Œäº†: {len(all_data)}éŠ˜æŸ„ã€‚ç‰¹å¾´é‡ç”Ÿæˆä¸­...")

            # ç‰¹å¾´é‡ç”Ÿæˆ (ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ã€é«˜é€Ÿ)
            for i, (ticker, df) in enumerate(all_data.items()):
                try:
                    features = fe.build_features(df)
                    labels = fe.create_labels(df)
                    feat_cols = fe.get_feature_columns()

                    valid = features[feat_cols].notna().all(axis=1) & labels.notna()
                    if valid.sum() > 20:
                        all_X.append(features.loc[valid, feat_cols])
                        all_y.append(labels[valid])
                        fetched_count += 1
                except Exception:
                    pass

            progress_phase2.progress(1.0, text=f"ç‰¹å¾´é‡ç”Ÿæˆå®Œäº† âœ… ({fetched_count}éŠ˜æŸ„)")

            if all_X:
                X_combined = pd.concat(all_X, ignore_index=True)
                y_combined = pd.concat(all_y, ignore_index=True)

                st.write(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(X_combined)} samples, æ€¥é¨°æ¯”ç‡: {y_combined.mean():.2%}")

                st.write("ğŸ§  **Phase 3/3**: LightGBMå­¦ç¿’ä¸­...")
                predictor = SurgePredictor()
                metrics = predictor.train(X_combined, y_combined, walk_forward=False)

                if 'error' not in metrics:
                    predictor.save()
                    st.write(f"âœ… å­¦ç¿’å®Œäº†!")
                    st.write(f"AUC: {metrics.get('auc_roc', 0):.3f}")
                    st.write(f"P@{ModelConfig.TOP_K}: {metrics.get('precision_at_k', 0):.3f}")
                    status.update(label="å­¦ç¿’å®Œäº†!", state="complete")

                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒªãƒ­ãƒ¼ãƒ‰
                    load_model.clear()
                else:
                    st.error(f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {metrics}")
                    status.update(label="å­¦ç¿’å¤±æ•—", state="error")
            else:
                st.error("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                status.update(label="ãƒ‡ãƒ¼ã‚¿ä¸è¶³", state="error")

st.sidebar.divider()

# Watchlist
st.sidebar.header("â­ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ")
watchlist_df = db.get_watchlist()
if not watchlist_df.empty:
    st.sidebar.write(f"ä¿å­˜æ¸ˆã¿: {len(watchlist_df)}ä»¶")
    for _, row in watchlist_df.iterrows():
        col1, col2 = st.sidebar.columns([3, 1])
        col1.write(row['ticker'])
        if col2.button("ğŸ—‘", key=f"rm_{row['ticker']}"):
            db.remove_from_watchlist(row['ticker'])
            st.rerun()
else:
    st.sidebar.info("ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã¯ç©ºã§ã™")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tabs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Œ å€‹åˆ¥éŠ˜æŸ„åˆ†æ",
    "ğŸ” ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°",
    "ğŸš€ æ€¥é¨°å€™è£œAIæ¤œçŸ¥",
    "ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
    "â­ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ"
])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tab 1: å€‹åˆ¥éŠ˜æŸ„åˆ†æ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab1:
    all_tickers = load_tickers()

    # æ¤œç´¢ç”¨ãƒªã‚¹ãƒˆ
    ticker_list = []
    if not all_tickers.empty:
        ticker_list = [f"{row.Name} ({row.Ticker})" for row in all_tickers.itertuples()]

    col1, col2 = st.columns([1, 4])
    with col1:
        ticker_input = st.text_input(
            "Ticker Symbol (ä¾‹: 7203.T)",
            value="7203.T",
            key="ticker_input_tab1"
        )

        options = ["æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›..."] + ticker_list
        selected = st.selectbox("éŠ˜æŸ„æ¤œç´¢", options, index=0, key="search_tab1")
        if selected != "æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›...":
            try:
                ticker_input = selected.split("(")[-1].replace(")", "")
            except Exception:
                pass

        period_input = st.selectbox("æœŸé–“", ["3mo", "6mo", "1y", "2y"], index=2)
        analyze_btn = st.button("ğŸ” åˆ†æé–‹å§‹", key="analyze_tab1")

    if analyze_btn and ticker_input:
        if not validate_ticker_symbol(ticker_input):
            st.error("ç„¡åŠ¹ãªãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã™")
        else:
            with st.spinner(f"{ticker_input} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                result = recommender.analyze_single(ticker_input, period=period_input)

            if 'error' in result:
                st.error(result['error'])
            else:
                df_chart = result['df']
                signals = result['signals']
                ml_prob = result['ml_prob']

                # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆè¿½åŠ ãƒœã‚¿ãƒ³
                with col2:
                    if not db.is_in_watchlist(ticker_input):
                        if st.button("â­ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«è¿½åŠ ", key="add_wl"):
                            db.add_to_watchlist(ticker_input)
                            st.rerun()

                # ãƒãƒ£ãƒ¼ãƒˆ
                fig = plot_stock_chart(df_chart, ticker_input)
                st.plotly_chart(fig, use_container_width=True)

                # MLç¢ºç‡è¡¨ç¤º
                if model.model is not None:
                    prob_col1, prob_col2 = st.columns([1, 4])
                    with prob_col1:
                        st.metric("ğŸ¤– MLæ€¥é¨°ç¢ºç‡", f"{ml_prob:.1%}")

                # ã‚·ã‚°ãƒŠãƒ«åˆ†æ
                st.subheader("ğŸ“Š ã‚·ã‚°ãƒŠãƒ«åˆ†æ")
                c1, c2, c3, c4 = st.columns(4)

                terms_map = {
                    'Short': ('ğŸ“ˆ çŸ­æœŸ', c1),
                    'Medium': ('ğŸ“Š ä¸­æœŸ', c2),
                    'Long': ('ğŸ“‰ é•·æœŸ', c3),
                }

                for term, (label, col) in terms_map.items():
                    res = signals[term]
                    with col:
                        st.markdown(f"### {label}")
                        score = res['score']
                        if score > 0:
                            st.success(f"Score: {score}")
                        elif score < 0:
                            st.error(f"Score: {score}")
                        else:
                            st.info(f"Score: {score}")
                        st.write(f"**Reason:** {res['reason']}")

                # ä»•æ‰‹æ ªåˆ¤å®š
                spec = result['speculative']
                with c4:
                    st.markdown("### ğŸ”¥ ä»•æ‰‹æ ªåˆ¤å®š")
                    if spec['is_speculative']:
                        st.warning(f"Score: {spec['score']}")
                    else:
                        st.info("ç‰¹ã«ãªã—")
                    st.write(f"Volæ¯”: {spec['vol_ratio']:.1f}x")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tab 2: ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab2:
    st.header("ğŸ” ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")

    all_tickers = load_tickers()

    if all_tickers.empty:
        st.error("éŠ˜æŸ„ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        sectors = sorted(all_tickers['Sector'].unique())
        selected_sector = st.selectbox("ã‚»ã‚¯ã‚¿ãƒ¼é¸æŠ", sectors, index=0, key="sector_tab2")

        target_term = st.selectbox(
            "ç›®æ¨™æœŸé–“",
            ["Short(çŸ­æœŸ)", "Medium(ä¸­æœŸ)", "Long(é•·æœŸ)"],
            index=1, key="term_tab2"
        )

        sector_tickers = all_tickers[all_tickers['Sector'] == selected_sector]
        st.write(f"**{len(sector_tickers)}** éŠ˜æŸ„ãŒ '{selected_sector}' ã‚»ã‚¯ã‚¿ãƒ¼ã«ã‚ã‚Šã¾ã™")

        if st.button("ğŸ”„ ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹", key="scan_tab2"):
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()

            term_key = target_term.split('(')[0]
            total = len(sector_tickers)

            for i, row in enumerate(sector_tickers.itertuples()):
                code = row.Ticker
                name = row.Name
                status_text.text(f"Scanning {code} ({name})...")

                df = get_stock_data(code, period="1y")
                if df is not None and not df.empty and len(df) >= 50:
                    try:
                        df_tech = add_technical_indicators(df)
                        res = analyze_term_signal(df_tech, term_key)
                        results.append({
                            'Ticker': code, 'Name': name,
                            'Score': res['score'],
                            'Reason': res['reason'],
                            'Price': df['Close'].iloc[-1],
                            'RSI': df_tech['RSI'].iloc[-1] if 'RSI' in df_tech.columns else None,
                        })
                    except Exception:
                        pass

                progress_bar.progress((i + 1) / total)
                time.sleep(0.3)

            status_text.text("ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†!")

            if results:
                res_df = pd.DataFrame(results).sort_values('Score', ascending=False)
                st.subheader(f"æ¨è–¦éŠ˜æŸ„ãƒ©ãƒ³ã‚­ãƒ³ã‚° ({target_term})")
                st.dataframe(res_df, use_container_width=True)
            else:
                st.info("æ¡ä»¶ã«åˆã†éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tab 3: æ€¥é¨°å€™è£œAIæ¤œçŸ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    st.header("ğŸš€ æ€¥é¨°å€™è£œAIæ¤œçŸ¥")
    st.markdown("""
    **LightGBM + ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«** ã§æ€¥é¨°å€™è£œã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    MLç¢ºç‡ã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚·ã‚°ãƒŠãƒ«ã‚’çµ±åˆã—ãŸã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¾ã™ã€‚
    """)

    if model.model is None:
        st.warning("âš ï¸ MLãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã§å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚")

    all_tickers = load_tickers()

    if not all_tickers.empty:
        scan_mode = st.radio(
            "ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰",
            ["ã‚»ã‚¯ã‚¿ãƒ¼æŒ‡å®š", "ä»•æ‰‹æ ªæ¤œçŸ¥ï¼ˆå‡ºæ¥é«˜æ€¥å¢—ï¼‰"],
            horizontal=True, key="mode_tab3"
        )

        if scan_mode == "ã‚»ã‚¯ã‚¿ãƒ¼æŒ‡å®š":
            sectors = sorted(all_tickers['Sector'].unique())
            selected_sector = st.selectbox("ã‚»ã‚¯ã‚¿ãƒ¼", sectors, key="sector_tab3")
            scan_tickers = all_tickers[all_tickers['Sector'] == selected_sector]['Ticker'].tolist()
        else:
            sectors = sorted(all_tickers['Sector'].unique())
            selected_sector = st.selectbox("ã‚»ã‚¯ã‚¿ãƒ¼ (ä»•æ‰‹æ ª)", sectors, key="spec_sector_tab3")
            scan_tickers = all_tickers[all_tickers['Sector'] == selected_sector]['Ticker'].tolist()

        st.write(f"ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡: **{len(scan_tickers)}** éŠ˜æŸ„")

        if st.button("ğŸš€ AIã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", key="ai_scan_tab3"):
            progress_bar = st.progress(0)
            status_text = st.empty()

            def progress_cb(current, total):
                progress_bar.progress(current / total)
                status_text.text(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­... ({current}/{total})")

            if scan_mode == "ã‚»ã‚¯ã‚¿ãƒ¼æŒ‡å®š":
                results_df = recommender.scan_with_ml(scan_tickers, progress_callback=progress_cb)
            else:
                results_df = recommender.scan_speculative(scan_tickers, progress_callback=progress_cb)

            status_text.text("ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†!")

            if not results_df.empty:
                st.subheader("ğŸ† æ¨è–¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°")

                # ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
                st.dataframe(
                    results_df.head(30),
                    use_container_width=True,
                    column_config={
                        "ML_Prob": st.column_config.ProgressColumn(
                            "MLç¢ºç‡", format="%.1f%%", min_value=0, max_value=1
                        ),
                        "Price": st.column_config.NumberColumn(
                            "æ ªä¾¡", format="Â¥%.0f"
                        ),
                    }
                )
            else:
                st.info("æ¡ä»¶ã«åˆã†éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tab 4: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab4:
    st.header("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    st.markdown("æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®éå»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚")

    from src.backtester import ROIBacktester

    col1, col2, col3 = st.columns(3)
    with col1:
        bt_capital = st.number_input("åˆæœŸè³‡é‡‘ (Â¥)", value=1_000_000, step=100_000)
    with col2:
        bt_positions = st.slider("æœ€å¤§ä¿æœ‰éŠ˜æŸ„æ•°", 1, 10, 5)
    with col3:
        bt_holding = st.slider("ä¿æœ‰æ—¥æ•°", 1, 20, 5)

    if st.button("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key="bt_tab4"):
        st.info("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã¯ã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¾Œã«ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’ç”¨ã„ã¦å®Ÿè¡Œã—ã¾ã™ã€‚")
        st.markdown("""
        **ä½¿ã„æ–¹**:
        1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        2. ã€Œæ€¥é¨°å€™è£œAIæ¤œçŸ¥ã€ã‚¿ãƒ–ã§ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œ
        3. éå»ã®æ¨è–¦çµæœã«åŸºã¥ã„ã¦ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ

        **è©•ä¾¡æŒ‡æ¨™**:
        - ç´¯ç©ROI (æŠ•è³‡åç›Šç‡)
        - ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
        - æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        - å‹ç‡
        """)

        # ãƒ‡ãƒ¢ç”¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        bt = ROIBacktester(
            initial_capital=bt_capital,
            max_positions=bt_positions,
            holding_days=bt_holding
        )

        if model.model is not None and model.metrics_:
            st.subheader("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")
            m = model.metrics_
            mc1, mc2, mc3, mc4 = st.columns(4)
            mc1.metric("AUC-ROC", f"{m.get('auc_roc', 0):.3f}")
            mc2.metric(f"Precision@{ModelConfig.TOP_K}", f"{m.get('precision_at_k', 0):.3f}")
            mc3.metric("F1-Score", f"{m.get('f1', 0):.3f}")
            mc4.metric("æ€¥é¨°ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{m.get('support_positive', 0)}")

        # ç‰¹å¾´é‡é‡è¦åº¦
        if model.model is not None:
            fi = model.get_feature_importance()
            if not fi.empty:
                st.subheader("ğŸ”‘ ç‰¹å¾´é‡é‡è¦åº¦ Top 20")
                import plotly.express as px
                fig = px.bar(
                    fi.head(20),
                    x='importance', y='feature',
                    orientation='h',
                    title='Feature Importance (Gain)',
                    labels={'importance': 'é‡è¦åº¦', 'feature': 'ç‰¹å¾´é‡'}
                )
                fig.update_layout(yaxis=dict(autorange="reversed"), height=500)
                st.plotly_chart(fig, use_container_width=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tab 5: ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab5:
    st.header("â­ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆç®¡ç†")

    # è¿½åŠ ãƒ•ã‚©ãƒ¼ãƒ 
    col1, col2, col3 = st.columns([2, 2, 1])
    with col1:
        new_ticker = st.text_input("ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚³ãƒ¼ãƒ‰", placeholder="ä¾‹: 7203.T", key="add_wl_input")
    with col2:
        new_note = st.text_input("ãƒ¡ãƒ¢", placeholder="æ³¨ç›®ç†ç”±", key="add_wl_note")
    with col3:
        st.write("")  # spacer
        st.write("")
        if st.button("â• è¿½åŠ ", key="add_wl_btn"):
            if new_ticker:
                db.add_to_watchlist(new_ticker, new_note)
                st.rerun()

    st.divider()

    # ä¸€è¦§è¡¨ç¤º
    wl = db.get_watchlist()
    if not wl.empty:
        st.dataframe(wl, use_container_width=True)

        # ä¸€æ‹¬åˆ†æ
        if st.button("ğŸ” ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆéŠ˜æŸ„ã‚’ä¸€æ‹¬åˆ†æ"):
            for _, row in wl.iterrows():
                ticker = row['ticker']
                with st.expander(f"ğŸ“Œ {ticker}"):
                    df = get_stock_data(ticker, period="6mo")
                    if df is not None and not df.empty:
                        df_tech = add_technical_indicators(df)
                        fig = plot_stock_chart(df_tech, ticker)
                        st.plotly_chart(fig, use_container_width=True)

                        # ã‚·ã‚°ãƒŠãƒ«
                        c1, c2, c3 = st.columns(3)
                        for term, col in zip(['Short', 'Medium', 'Long'], [c1, c2, c3]):
                            res = analyze_term_signal(df_tech, term)
                            with col:
                                st.metric(term, res['score'])
                    else:
                        st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
    else:
        st.info("ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«éŠ˜æŸ„ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
